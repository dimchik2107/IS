{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1eae7e0-2e5b-42a1-8c46-2adefb86382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d79f312e-5255-47e9-ac1b-8ff4cfa4df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "625/625 [==============================] - 826s 1s/step - loss: 0.4141 - accuracy: 0.8086 - val_loss: 0.3162 - val_accuracy: 0.8747\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 539s 863ms/step - loss: 0.2721 - accuracy: 0.8920 - val_loss: 0.2924 - val_accuracy: 0.8850\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 563s 900ms/step - loss: 0.3985 - accuracy: 0.8186 - val_loss: 0.3555 - val_accuracy: 0.8524\n",
      "Accuracy: 85.24%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "\n",
    "top_words = 5000\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "X_test = data[:10000] \n",
    "y_test = targets[:10000]\n",
    "X_train = data[10000:]\n",
    "y_train = targets[10000:]\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 # длина вектора, в котором будут представляться слова  \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length)) # плотный вектор\n",
    "# input_length - размер входных данных\n",
    "model.add(LSTM(100)) # рекуррентный слой\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd85fea6-03d3-42ca-a928-08ff48d0eaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 216,405\n",
      "Trainable params: 216,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "625/625 [==============================] - 255s 402ms/step - loss: 0.3720 - accuracy: 0.8227 - val_loss: 0.2937 - val_accuracy: 0.8870\n",
      "Epoch 2/3\n",
      "625/625 [==============================] - 232s 371ms/step - loss: 0.2371 - accuracy: 0.9075 - val_loss: 0.2667 - val_accuracy: 0.8907\n",
      "Epoch 3/3\n",
      "625/625 [==============================] - 246s 394ms/step - loss: 0.2025 - accuracy: 0.9226 - val_loss: 0.2688 - val_accuracy: 0.8936\n",
      "Accuracy: 89.36%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "\n",
    "top_words = 5000\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "X_test = data[:10000] \n",
    "y_test = targets[:10000]\n",
    "X_train = data[10000:]\n",
    "y_train = targets[10000:]\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 #на вход получает номера слов, а на выходе выдаёт их векторные представления \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) # сверточный слой\n",
    "model.add(MaxPooling1D(pool_size=2)) # субдискретизирующий слой\n",
    "model.add(LSTM(100)) # рекуррентный слой\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77094f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 567s 717ms/step - loss: 0.3510 - accuracy: 0.8393 - val_loss: 0.2697 - val_accuracy: 0.9000\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 869s 1s/step - loss: 0.2340 - accuracy: 0.9077 - val_loss: 0.1245 - val_accuracy: 0.9560\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 721s 921ms/step - loss: 0.1977 - accuracy: 0.9242 - val_loss: 0.1175 - val_accuracy: 0.9680\n",
      "Accuracy: 96.80%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "\n",
    "top_words = 5000\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "X_test = data[:250] \n",
    "y_test = targets[:250]\n",
    "X_train = data[1:]\n",
    "y_train = targets[1:]\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 #на вход получает номера слов, а на выходе выдаёт их векторные представления \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) # сверточный слой\n",
    "model.add(MaxPooling1D(pool_size=2)) # субдискретизирующий слой\n",
    "model.add(LSTM(100)) # рекуррентный слой\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de7f1146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great movie really liked the actor in the title role, good quality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE 0.89122504'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(txt:str):\n",
    "    txt = txt.lower()\n",
    "    txt1 = \"\"\n",
    "    for i in txt:\n",
    "        if('a'<=i<='z' or i==' '):\n",
    "            txt1+=i\n",
    "    txt1=txt1.split()\n",
    "    index = imdb.get_word_index()\n",
    "    tokens=np.array([min(index.get(i, 5000),5000)+3 for i in txt1])\n",
    "    vector = sequence.pad_sequences([tokens], maxlen=max_review_length)\n",
    "    p=model.predict(vector)[0][0]\n",
    "    return \"POSITIVE \"+str(p) if p>0.5 else \"NEGATIVE \"+str(1-p)\n",
    "\n",
    "predict(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd29a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
