{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3882ce09-f69b-4ba4-acb3-9bfe05bc3934",
   "metadata": {},
   "source": [
    "###### Министерство цифрового развития, связи и массовых коммуникаций\n",
    "###### Российской Федерации\n",
    "###### Ордена Трудового Красного Знамени федеральное государственное\n",
    "###### бюджетное образовательное учреждение высшего образования\n",
    "###### “Московский технический университет связи и информатики”\n",
    "\n",
    "## Лабораторная работа №7\n",
    "### \"Классификация обзоров фильмов\"\n",
    "\n",
    "### Выполнила: студентка группы БФИ1901\n",
    "### Струкова Алиса\n",
    "\n",
    "\n",
    "### Цель:\n",
    "Классификация последовательностей - это проблема прогнозирующего моделирования,\n",
    "когда у вас есть некоторая последовательность входных данных в пространстве или\n",
    "времени, и задача состоит в том, чтобы предсказать категорию для последовательности.\n",
    "Проблема усложняется тем, что последовательности могут различаться по длине,\n",
    "состоять из очень большого словарного запаса входных символов и могут потребовать от\n",
    "модели изучения долгосрочного контекста или зависимостей между символами во входной\n",
    "последовательности.\n",
    "В данной лабораторной работе также будет использоваться датасет IMDb, однако\n",
    "обучение будет проводиться с помощью рекуррентной нейронной сети.\n",
    "\n",
    "\n",
    "### Задачи:\n",
    "1. Ознакомиться с рекуррентными нейронными сетями\n",
    "2. Изучить способы классификации текста\n",
    "3. Ознакомиться с ансамблированием сетей\n",
    "4. Построить ансамбль сетей, который позволит получать точность не менее 97%\n",
    "\n",
    "### Выполнение работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3425fe26-7392-42f2-a62d-00e66314fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3dd518de-bd4d-4431-8575-e1cabf56b261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_40 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm_38 (LSTM)              (None, 100)               53200     \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "391/391 [==============================] - 274s 698ms/step - loss: 0.4546 - accuracy: 0.7808 - val_loss: 0.3384 - val_accuracy: 0.8598\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 257s 657ms/step - loss: 0.2817 - accuracy: 0.8875 - val_loss: 0.3249 - val_accuracy: 0.8646\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 244s 625ms/step - loss: 0.2828 - accuracy: 0.8860 - val_loss: 0.3217 - val_accuracy: 0.8664\n",
      "Accuracy: 86.64%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    " #Далее нам нужно обрезать и дополнить входные последовательности так, чтобы они были\n",
    "#одинаковой длины для моделирования. Модель узнает, что нулевые значения не содержат\n",
    "#никакой информации, поэтому на самом деле последовательности имеют разную длину с\n",
    "#точки зрения содержания, но для выполнения вычислений в Керасе требуются векторы\n",
    "#одинаковой длины.\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 #на вход получает номера слов, а на выходе выдаёт их векторные представления \n",
    "\n",
    "model = Sequential()\n",
    "#векторизуем\n",
    "model.add(Embedding(top_words, embedding_vecor_length,\n",
    "input_length=max_review_length))\n",
    "#LSTM разработаны специально, чтобы избежать проблемы долговременной зависимости. 100 единицами памяти\n",
    "model.add(LSTM(100)) \n",
    "#поскольку это проблема классификации, мы используем плотный\n",
    "#выходной слой с одним нейроном и сигмоидной функцией активации, чтобы сделать 0 или\n",
    "#1 прогноз для двух классов (хорошего и плохого) в задаче.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n",
    "#model = Sequential()\n",
    "#model.add(Embedding(top_words, embedding_vecor_length,\n",
    "#input_length=max_review_length))\n",
    "#model.add(Conv1D(filters=32, kernel_size=3, padding='same',\n",
    "#activation='relu'))\n",
    "#model.add(MaxPooling1D(pool_size=2))\n",
    "#model.add(LSTM(100))\n",
    "#model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fb34cc-a3ba-4ac9-b28d-fbca987288d8",
   "metadata": {},
   "source": [
    "### LSTM и сверточная нейронная сеть для классификации последовательностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61c20d62-4114-43d9-b0c1-f4429d5ce419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 250, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 100)               53200     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 216,405\n",
      "Trainable params: 216,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "391/391 [==============================] - 126s 318ms/step - loss: 0.4333 - accuracy: 0.7914 - val_loss: 0.3067 - val_accuracy: 0.8749\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 113s 290ms/step - loss: 0.2603 - accuracy: 0.8984 - val_loss: 0.3189 - val_accuracy: 0.8718\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 119s 303ms/step - loss: 0.2025 - accuracy: 0.9228 - val_loss: 0.3184 - val_accuracy: 0.8706\n",
      "Accuracy: 87.06%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length,\n",
    "input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bafc43-7386-4dd5-945c-23b6e5d0d313",
   "metadata": {},
   "source": [
    "## Теория\n",
    "Идея RNN заключается в последовательном использовании информации. В традиционных нейронных сетях подразумевается, что все входы и выходы независимы. Но для многих задач это не подходит. Если вы хотите предсказать следующее слово в предложении, лучше учитывать предшествующие ему слова. RNN называются рекуррентными, потому что они выполняют одну и ту же задачу для каждого элемента последовательности, причем выход зависит от предыдущих вычислений. Еще одна интерпретация RNN: это сети, у которых есть «память», которая учитывает предшествующую информацию. Теоретически RNN могут использовать информацию в произвольно длинных последовательностях, но на практике они ограничены лишь несколькими шагами\n",
    "\n",
    "Вообще говоря, мы используем слой внедрения, чтобы сжать пространство входных объектов в меньший.\n",
    "\n",
    "!!! LSTM- нужны когда нужен контекст\n",
    "LSTM - Долгая краткосрочная память. LSTM разработаны специально, чтобы избежать проблемы долговременной зависимости. Запоминание информации на долгие периоды времени – это их обычное поведение, а не что-то, чему они с трудом пытаются обучиться.\n",
    "LSTM-модули разработаны специально, чтобы избежать проблемы долговременной зависимости, запоминая значения как на короткие, так и на длинные промежутки времени. Это объясняется тем, что LSTM-модуль не использует функцию активации внутри своих рекуррентных компонентов. Таким образом, хранимое значение не размывается во времени и градиент не исчезает при использовании метода обратного распространения ошибки во времени (англ. Backpropagation Through Time, BPTT) при тренировке сети.\n",
    "\n",
    "\n",
    "ансамблевые модели - это как раз модели, состоящие из комбинации базовых моделей. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9aff9-ed43-40bc-a3f0-17abd3909e22",
   "metadata": {},
   "source": [
    "## Архитектура сети со слоями Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df19734f-068b-4a8c-83dd-9974e05ade95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_12 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 500, 32)           0         \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 500, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_8 (MaxPooling  (None, 250, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 250, 32)           0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 100)               53200     \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 219,509\n",
      "Trainable params: 219,509\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/4\n",
      "782/782 [==============================] - 146s 185ms/step - loss: 0.4355 - accuracy: 0.7836 - val_loss: 0.2911 - val_accuracy: 0.8811\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 142s 181ms/step - loss: 0.2712 - accuracy: 0.8898 - val_loss: 0.3485 - val_accuracy: 0.8651\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 140s 179ms/step - loss: 0.2236 - accuracy: 0.9151 - val_loss: 0.2727 - val_accuracy: 0.8876\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 0.1965 - accuracy: 0.9253 - val_loss: 0.2863 - val_accuracy: 0.8800\n",
      "Accuracy: 88.00%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(LSTM(100))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=32)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a650e61d-2ef3-4c9f-8845-f214169cea0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_14 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 500, 32)           0         \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 500, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_10 (MaxPoolin  (None, 250, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 250, 32)           0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 100)               53200     \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                3232      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 222,673\n",
      "Trainable params: 222,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "782/782 [==============================] - 128s 162ms/step - loss: 0.5299 - accuracy: 0.7201 - val_loss: 0.3902 - val_accuracy: 0.8317\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 135s 173ms/step - loss: 0.3366 - accuracy: 0.8614 - val_loss: 0.3727 - val_accuracy: 0.8272\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 137s 175ms/step - loss: 0.2712 - accuracy: 0.8909 - val_loss: 0.2938 - val_accuracy: 0.8746\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 133s 169ms/step - loss: 0.2279 - accuracy: 0.9113 - val_loss: 0.2963 - val_accuracy: 0.8754\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 132s 169ms/step - loss: 0.2077 - accuracy: 0.9203 - val_loss: 0.3072 - val_accuracy: 0.8779\n",
      "Accuracy: 87.79%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(LSTM(100))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f1e40eb-ee86-4051-98e2-466b31d1ff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_16 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 500, 32)           0         \n",
      "                                                                 \n",
      " conv1d_17 (Conv1D)          (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " conv1d_18 (Conv1D)          (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 500, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPoolin  (None, 250, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 250, 32)           0         \n",
      "                                                                 \n",
      " lstm_14 (LSTM)              (None, 100)               53200     \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                6464      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 227,985\n",
      "Trainable params: 227,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/4\n",
      "782/782 [==============================] - 147s 187ms/step - loss: 0.5696 - accuracy: 0.6926 - val_loss: 0.3964 - val_accuracy: 0.8355\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 154s 197ms/step - loss: 0.3366 - accuracy: 0.8616 - val_loss: 0.3003 - val_accuracy: 0.8762\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 149s 190ms/step - loss: 0.2494 - accuracy: 0.9015 - val_loss: 0.2782 - val_accuracy: 0.8831\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 139s 177ms/step - loss: 0.2142 - accuracy: 0.9179 - val_loss: 0.2756 - val_accuracy: 0.8890\n",
      "Accuracy: 88.90%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(LSTM(100))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=32)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "20dca702-c917-4e49-bb05-7ab7c1900e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 431s 549ms/step - loss: 0.3978 - accuracy: 0.8231 - val_loss: 0.1751 - val_accuracy: 0.9320\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 468s 598ms/step - loss: 0.2699 - accuracy: 0.8921 - val_loss: 0.1922 - val_accuracy: 0.9200\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 430s 550ms/step - loss: 0.2329 - accuracy: 0.9077 - val_loss: 0.1392 - val_accuracy: 0.9480\n",
      "Accuracy: 94.80%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "\n",
    "top_words = 5000\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "X_test = data[:250]\n",
    "y_test = targets[:250]\n",
    "X_train = data[1:]\n",
    "y_train = targets[1:]\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 # длина вектора, в котором будут представляться слова\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length)) # плотный вектор\n",
    "# input_length - размер входных данных\n",
    "model.add(LSTM(100)) # рекуррентный слой\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4b255e0e-277b-4525-bb31-cdb833612794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_53\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_46 (Embedding)    (None, 500, 32)           64000     \n",
      "                                                                 \n",
      " dropout_136 (Dropout)       (None, 500, 32)           0         \n",
      "                                                                 \n",
      " conv1d_61 (Conv1D)          (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " dropout_137 (Dropout)       (None, 500, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_35 (MaxPoolin  (None, 250, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_138 (Dropout)       (None, 250, 32)           0         \n",
      "                                                                 \n",
      " lstm_44 (LSTM)              (None, 100)               53200     \n",
      "                                                                 \n",
      " dropout_139 (Dropout)       (None, 100)               0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 120,405\n",
      "Trainable params: 120,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/4\n",
      "782/782 [==============================] - 176s 223ms/step - loss: 0.3985 - accuracy: 0.8088 - val_loss: 0.2749 - val_accuracy: 0.8840\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 173s 221ms/step - loss: 0.2844 - accuracy: 0.8846 - val_loss: 0.2539 - val_accuracy: 0.8940\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 168s 215ms/step - loss: 0.2679 - accuracy: 0.8919 - val_loss: 0.2380 - val_accuracy: 0.9060\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 169s 216ms/step - loss: 0.2548 - accuracy: 0.8990 - val_loss: 0.2216 - val_accuracy: 0.9020\n",
      "Accuracy: 90.20%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "\n",
    "top_words = 2000\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "X_test = data[:500]\n",
    "y_test = targets[:500]\n",
    "X_train = data[1:]\n",
    "y_train = targets[1:]\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(LSTM(100))\n",
    "model.add(layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4d10df40-7c24-4b15-99d5-91a798559e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_54\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_47 (Embedding)    (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " dropout_140 (Dropout)       (None, 500, 32)           0         \n",
      "                                                                 \n",
      " conv1d_62 (Conv1D)          (None, 500, 32)           3104      \n",
      "                                                                 \n",
      " dropout_141 (Dropout)       (None, 500, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_36 (MaxPoolin  (None, 250, 32)          0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout_142 (Dropout)       (None, 250, 32)           0         \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 100)               53200     \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 216,405\n",
      "Trainable params: 216,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/4\n",
      "782/782 [==============================] - 200s 255ms/step - loss: 0.3836 - accuracy: 0.8147 - val_loss: 0.2418 - val_accuracy: 0.9240\n",
      "Epoch 2/4\n",
      "782/782 [==============================] - 198s 254ms/step - loss: 0.2425 - accuracy: 0.9046 - val_loss: 0.1907 - val_accuracy: 0.9280\n",
      "Epoch 3/4\n",
      "782/782 [==============================] - 198s 253ms/step - loss: 0.2153 - accuracy: 0.9162 - val_loss: 0.1311 - val_accuracy: 0.9520\n",
      "Epoch 4/4\n",
      "782/782 [==============================] - 198s 253ms/step - loss: 0.1941 - accuracy: 0.9251 - val_loss: 0.1003 - val_accuracy: 0.9760\n",
      "Accuracy: 97.60%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "\n",
    "top_words = 5000\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "X_test = data[:250]\n",
    "y_test = targets[:250]\n",
    "X_train = data[1:]\n",
    "y_train = targets[1:]\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 # длина вектора, в котором будут представляться слова\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(layers.Dropout(0.2, noise_shape=None, seed=None))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9153670a-daf7-4573-b824-a7f5639c7f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
