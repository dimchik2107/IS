{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc446d7d-265d-4eeb-ad7b-242459914164",
   "metadata": {},
   "source": [
    "# Лабораторная работа № 7\n",
    "\n",
    "Классификация обзоров фильмов\n",
    "\n",
    "Выполнил:\n",
    "    Студент группы БФИ1901\n",
    "    Чернышов Дмитрий\n",
    "    \n",
    "Задачи:\n",
    "\n",
    "   1. Ознакомиться с рекуррентными нейронными сетями\n",
    "   2. Изучить способы классификации текста\n",
    "   3. Ознакомиться с ансамблированием сетей\n",
    "   4. Построить ансамбль сетей, который позволит получать точность не менее 97%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282579c0",
   "metadata": {},
   "source": [
    "# Цель работы:\n",
    "Классификация последовательностей - это проблема прогнозирующего моделирования,\n",
    "когда у вас есть некоторая последовательность входных данных в пространстве или\n",
    "времени, и задача состоит в том, чтобы предсказать категорию для последовательности.\n",
    "Проблема усложняется тем, что последовательности могут различаться по длине,\n",
    "состоять из очень большого словарного запаса входных символов и могут потребовать от\n",
    "модели изучения долгосрочного контекста или зависимостей между символами во входной\n",
    "последовательности.\n",
    "В данной лабораторной работе также будет использоваться датасет IMDb, однако\n",
    "обучение будет проводиться с помощью рекуррентной нейронной сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4394b0da-c0a2-45cf-837b-6c996fdee9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "import tkinter as tk\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20acf963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 500, 32)           160000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               53200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "391/391 [==============================] - 280s 712ms/step - loss: 0.4558 - accuracy: 0.7813 - val_loss: 0.6333 - val_accuracy: 0.7905\n",
      "Epoch 2/3\n",
      "391/391 [==============================] - 247s 631ms/step - loss: 0.2892 - accuracy: 0.8855 - val_loss: 0.3054 - val_accuracy: 0.8738\n",
      "Epoch 3/3\n",
      "391/391 [==============================] - 249s 638ms/step - loss: 0.2608 - accuracy: 0.8967 - val_loss: 0.3163 - val_accuracy: 0.8728\n",
      "Accuracy: 87.28%\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length) #длина отзыва 500 слов\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 #на вход получает номера слов, а на выходе выдаёт их векторные представления \n",
    "\n",
    "model = Sequential()\n",
    "#векторизуем\n",
    "model.add(Embedding(top_words, embedding_vecor_length,\n",
    "input_length=max_review_length))\n",
    "#LSTM разработаны специально, чтобы избежать проблемы долговременной зависимости. 100 единицами памяти\n",
    "model.add(LSTM(100)) \n",
    "#поскольку это проблема классификации, мы используем плотный\n",
    "#выходной слой с одним нейроном и сигмоидной функцией активации, чтобы сделать 0 или\n",
    "#1 прогноз для двух классов (хорошего и плохого) в задаче.\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84cc0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length,\n",
    "input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
    "epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9058b18",
   "metadata": {},
   "source": [
    "# Архитектура сети со слоями Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2db07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(keras.layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(keras.layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(keras.layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(LSTM(100))\n",
    "model.add(keras.layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4, batch_size=32)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fbe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import imdb\n",
    "(training_data, training_targets), (testing_data,\n",
    "testing_targets) = imdb.load_data(num_words=10000)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "\n",
    "targets = np.concatenate((training_targets, testing_targets),\n",
    "axis=0)\n",
    "\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train,\n",
    "maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test,\n",
    "maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(keras.layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) #filters - Количество выходных фильтров в свертке\n",
    "model.add(keras.layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(keras.layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(LSTM(100))\n",
    "model.add(keras.layers.Dropout(0.3, noise_shape=None, seed=None))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e1850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "\n",
    "top_words = 5000\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "X_test = data[:250]\n",
    "y_test = targets[:250]\n",
    "X_train = data[1:]\n",
    "y_train = targets[1:]\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 # длина вектора, в котором будут представляться слова\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length)) # плотный вектор\n",
    "# input_length - размер входных данных\n",
    "model.add(LSTM(100)) # рекуррентный слой\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd196d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb #Загружаем датесет IMDb,\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import imdb\n",
    "\n",
    "top_words = 5000\n",
    "(training_data, training_targets), (testing_data, testing_targets) = imdb.load_data(num_words=top_words)\n",
    "data = np.concatenate((training_data, testing_data), axis=0)\n",
    "targets = np.concatenate((training_targets, testing_targets), axis=0)\n",
    "\n",
    "X_test = data[:270] \n",
    "y_test = targets[:270]\n",
    "X_train = data[1:]\n",
    "y_train = targets[1:]\n",
    "\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "\n",
    "embedding_vecor_length = 32 #на вход получает номера слов, а на выходе выдаёт их векторные представления \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu')) # сверточный слой\n",
    "model.add(MaxPooling1D(pool_size=2)) # субдискретизирующий слой\n",
    "model.add(LSTM(100)) # рекуррентный слой\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',\n",
    "metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3, batch_size=64)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dd1d8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great movie really liked the actor in the title role, good quality\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE 0.89095867'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = imdb.get_word_index()\n",
    "def predict(txt:str):\n",
    "    txt = txt.lower()\n",
    "    txt1 = \"\"\n",
    "    for i in txt:\n",
    "        if('a'<=i<='z' or i==' '):\n",
    "            txt1+=i\n",
    "    txt1=txt1.split()\n",
    "    tokens=np.array([min(index.get(i, 5000),5000)+3 for i in txt1])\n",
    "    vector = sequence.pad_sequences([tokens], maxlen=max_review_length)\n",
    "    p=model.predict(vector)[0][0]\n",
    "    return \"POSITIVE \"+str(p) if p>0.5 else \"NEGATIVE \"+str(1-p)\n",
    "\n",
    "predict(input())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dcda7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
